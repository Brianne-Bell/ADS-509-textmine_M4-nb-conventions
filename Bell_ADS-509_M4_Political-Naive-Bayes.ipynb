{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brianne Bell\n",
    "## ADS 509 Module 4: Naive Bayes on Political Text\n",
    "### February 6, 2023\n",
    "\n",
    "In this notebook we use Naive Bayes to explore and classify political data. See the `README.md` for full details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import os\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "# Feel free to include your text patterns functions\n",
    "#from text_functions_solutions import clean_tokenize, get_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text patterns functions from module 3:\n",
    "# Some punctuation variations\n",
    "punctuation = set(punctuation) # speeds up comparison\n",
    "tw_punct = punctuation - {\"#\"}\n",
    "\n",
    "# Stopwords\n",
    "sw = stopwords.words(\"english\")\n",
    "\n",
    "# Two useful regex\n",
    "whitespace_pattern = re.compile(r\"\\s+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_db = sqlite3.connect(\"2020_Conventions.db\")\n",
    "convention_cur = convention_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conventions\n"
     ]
    }
   ],
   "source": [
    "# getting table name(s):\n",
    "con_tables = convention_db.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "for name in con_tables.fetchall():\n",
    "    print(name[0])\n",
    "# https://stackoverflow.com/questions/34570260/how-to-get-table-names-using-sqlite3-through-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['party', 'night', 'speaker', 'speaker_count', 'time', 'text', 'text_len', 'file']\n"
     ]
    }
   ],
   "source": [
    "# seeing what is in the <conventions> table\n",
    "convention_db.row_factory = sqlite3.Row\n",
    "concursor = convention_db.execute(\"SELECT * FROM conventions\") # select all from table\n",
    "conrow = concursor.fetchone()\n",
    "connames = conrow.keys()\n",
    "print(connames)\n",
    "\n",
    "# https://stackoverflow.com/questions/7831371/is-there-a-way-to-get-a-list-of-column-names-in-sqlite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The convention database is in table: conventions. This table has 'party', 'night', 'speaker', 'speaker_count', 'time', 'text', 'text_len', and 'file'. We will want 'party' and 'text' (as mentioned in next section)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Exploratory Naive Bayes\n",
    "\n",
    "We'll first build a NB model on the convention data itself, as a way to understand what words distinguish between the two parties. This is analogous to what we did in the \"Comparing Groups\" class work. First, pull in the text \n",
    "for each party and prepare it for use in Naive Bayes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_data = []\n",
    "\n",
    "# fill this list up with items that are themselves lists. The \n",
    "# first element in the sublist should be the cleaned and tokenized\n",
    "# text in a single string. The second element should be the party. \n",
    "\n",
    "query_results = convention_cur.execute(\n",
    "                            '''\n",
    "                            SELECT text, party FROM conventions\n",
    "                            ''')\n",
    "\n",
    "# Functions for cleaning text:\n",
    "## Removing Stop Tokens\n",
    "def remove_stop(tokens) :\n",
    "    # modify this function to remove stopwords\n",
    "    return [i for i in tokens if i.lower() not in sw]\n",
    "\n",
    "## Removing Punctiation (but not hashtags)\n",
    "def remove_punctuation(text, punct_set=tw_punct) : \n",
    "    return(\"\".join([ch for ch in text if ch not in punct_set]))\n",
    "\n",
    "## Tokenization Function with split on whitespace\n",
    "def tokenize(text) : \n",
    "    \"\"\" Splitting on whitespace rather than the book's tokenize function. That \n",
    "        function will drop tokens like '#hashtag' or '2A', which we need for Twitter. \"\"\"\n",
    "    \n",
    "    # modify this function to return tokens\n",
    "    return(i for i in whitespace_pattern.split(text))\n",
    "\n",
    "## Prepare Function\n",
    "def prepare(text, pipeline) : \n",
    "    tokens = str(text)\n",
    "    \n",
    "    for transform in pipeline : \n",
    "        tokens = transform(tokens)\n",
    "        \n",
    "    return(tokens)\n",
    "\n",
    "my_pipeline = [str.lower, remove_punctuation, tokenize, remove_stop]\n",
    "\n",
    "# moving on to calling functions\n",
    "for row in query_results :\n",
    "    text, party = row # each row of query result will have text and party\n",
    "    prep_text = prepare(text, pipeline= my_pipeline) # calling pipeline of functions for text\n",
    "    \n",
    "    # making tokens into string of words:\n",
    "    speeches = \" \".join(prep_text)\n",
    "    convention_data.append([speeches, party])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some random entries and see if they look right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['three bond forged sorrow expanded joy jill entered', 'Democratic'],\n",
       " ['thanks voters across country red states blue states â€“ n fried kimpson j nez r',\n",
       "  'Democratic'],\n",
       " ['heâ€™ll treat everyone respect matter', 'Democratic'],\n",
       " ['almost four years ago went election day completely underestimated despite said year know americans go polls behalf families economy national security childrenâ€™s future vote ideas partisan vote common sense vote goals hopes believe believe need husbandâ€™s leadership ever order bring us back greatest economy strongest country ever known god bless families god bless united states america related transcripts iowa gov kim reynolds press conference transcript september 16 â€¢ 46 mins ago press secretary kayleigh mcenany white house press conference transcript september 16 â€¢ 58 mins ago doj press conference transcript september 16 charges 5 chinese nationals â€¢ 2 hours ago rnc night 2 rnc night 2 first lady melania trump secretary state mike pompeo eric trump speak second night republican national convention watch speeches live posted npr tuesday august 25 2020 stay updated get weekly digest weekâ€™s important transcripts inbox itâ€™s news without news please enable javascript browser complete form email kind transcripts want read submit transcription overview works faq mobile app captions overview works faq caption converter subtitles translation overview certified translation business translation faq request quote company press careers freelancers blog api get touch 222 kearny st 8th floor san francisco ca 94108 contact us 8883690701 supportrevcom Â© revcom reviews terms privacy stay updated get weekly digest weekâ€™s important transcripts inbox itâ€™s news without news please enable javascript browser complete form email kind transcripts want read submit stay updated get weekly digest weekâ€™s important transcripts inbox itâ€™s news without news please enable javascript browser complete form email kind transcripts want read submit stay updated get weekly digest weekâ€™s important transcripts inbox itâ€™s news without news please enable javascript browser complete form email kind transcripts want read submit ',\n",
       "  'Republican'],\n",
       " [' singing', 'Democratic'],\n",
       " ['nothing one stop voting election', 'Democratic'],\n",
       " ['iâ€™m proud embrace multicultural identity greatest strength iâ€™m proud new mexico shown climate leadership looks like trump administration eliminating environmental protections weâ€™ve expanded theyâ€™ve rolling back regulations oil gas weâ€™ve taken polluters held accountable',\n",
       "  'Democratic'],\n",
       " ['cory would say clearly important election modern history country joe biden human empathetic honest decent particular moment american history god something country absolutely needs us whether youâ€™re progressives whether moderates conservatives got come together defeat president',\n",
       "  'Democratic'],\n",
       " ['state sovereignty', 'Republican'],\n",
       " ['good evening speaker house itâ€™s honor bring greetings house democrats diverse majority history 60 women people color lgbtq diversity strength unity power month america marks centennial women finally winning right vote 105 women house proudly 90 democrats win vote women marched fought never gave stand shoulders charged carrying forward unfinished work nation advanced heroes seneca falls selma stonewall four years ago president obama vice president biden white house made us proud leadership made country great spirit come together decry darkness light way forward country',\n",
       "  'Democratic']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(convention_data,k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that looks good, we now need to make our function to turn these into features. In my solution, I wanted to keep the number of features reasonable, so I only used words that occur at least `word_cutoff` times. Here's the code to test that if you want it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a word cutoff of 5, we have 2391 as features in the model.\n"
     ]
    }
   ],
   "source": [
    "word_cutoff = 5\n",
    "\n",
    "tokens = [w for t, p in convention_data for w in t.split()]\n",
    "\n",
    "word_dist = nltk.FreqDist(tokens)\n",
    "\n",
    "feature_words = set()\n",
    "\n",
    "for word, count in word_dist.items() :\n",
    "    if count > word_cutoff :\n",
    "        feature_words.add(word)\n",
    "        \n",
    "print(f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} as features in the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_features(text,fw) :\n",
    "    \"\"\"Given some text, this returns a dictionary holding the\n",
    "       feature words.\n",
    "       \n",
    "       Args: \n",
    "            * text: a piece of text in a continuous string. Assumes\n",
    "            text has been cleaned and case folded.\n",
    "            * fw: the *feature words* that we're considering. A word \n",
    "            in `text` must be in fw in order to be returned. This \n",
    "            prevents us from considering very rarely occurring words.\n",
    "        \n",
    "       Returns: \n",
    "            A dictionary with the words in `text` that appear in `fw`. \n",
    "            Words are only counted once. \n",
    "            If `text` were \"quick quick brown fox\" and `fw` = {'quick','fox','jumps'},\n",
    "            then this would return a dictionary of \n",
    "            {'quick' : True,\n",
    "             'fox' :    True}\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Your code here\n",
    "    \n",
    "    ret_dict = dict()\n",
    "    for i in text.split(): # looping through\n",
    "        if i in fw: # checking to see if i is in fw (feature word)\n",
    "            ret_dict[i] = True # if it is then respond with true\n",
    "    \n",
    "    return(ret_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert question 1\n",
    "assert(len(feature_words)>0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert question 2\n",
    "assert(conv_features(\"donald is the president\",feature_words)==\n",
    "       {'donald':True,'president':True})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert question 3\n",
    "assert(conv_features(\"people are american in america\",feature_words)==\n",
    "                     {'america':True,'american':True,\"people\":True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll build our feature set. Out of curiosity I did a train/test split to see how accurate the classifier was, but we don't strictly need to since this analysis is exploratory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(conv_features(text,feature_words), party) for (text, party) in convention_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20220507)\n",
    "random.shuffle(featuresets)\n",
    "\n",
    "test_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "test_set, train_set = featuresets[:test_size], featuresets[test_size:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                   china = True           Republ : Democr =     25.8 : 1.0\n",
      "                   votes = True           Democr : Republ =     23.8 : 1.0\n",
      "             enforcement = True           Republ : Democr =     21.5 : 1.0\n",
      "                 destroy = True           Republ : Democr =     19.2 : 1.0\n",
      "                freedoms = True           Republ : Democr =     18.2 : 1.0\n",
      "                 climate = True           Democr : Republ =     17.8 : 1.0\n",
      "                supports = True           Republ : Democr =     17.1 : 1.0\n",
      "                   crime = True           Republ : Democr =     16.1 : 1.0\n",
      "                   media = True           Republ : Democr =     14.9 : 1.0\n",
      "                 beliefs = True           Republ : Democr =     13.0 : 1.0\n",
      "               countries = True           Republ : Democr =     13.0 : 1.0\n",
      "                 defense = True           Republ : Democr =     13.0 : 1.0\n",
      "                    isis = True           Republ : Democr =     13.0 : 1.0\n",
      "                 liberal = True           Republ : Democr =     13.0 : 1.0\n",
      "                religion = True           Republ : Democr =     13.0 : 1.0\n",
      "                   trade = True           Republ : Democr =     12.7 : 1.0\n",
      "                    flag = True           Republ : Democr =     12.1 : 1.0\n",
      "               greatness = True           Republ : Democr =     12.1 : 1.0\n",
      "                 abraham = True           Republ : Democr =     11.9 : 1.0\n",
      "                  defund = True           Republ : Democr =     11.9 : 1.0\n",
      "                    drug = True           Republ : Democr =     10.9 : 1.0\n",
      "              department = True           Republ : Democr =     10.9 : 1.0\n",
      "               destroyed = True           Republ : Democr =     10.9 : 1.0\n",
      "                   enemy = True           Republ : Democr =     10.9 : 1.0\n",
      "               amendment = True           Republ : Democr =     10.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a little prose here about what you see in the classifier. Anything odd or interesting?\n",
    "\n",
    "### My Observations\n",
    "\n",
    "Republications dominate the top 25 informative features by using them 23 of the 25 times. Democrats featured the top feature when using 'votes' and 'climate' which reflects the Democratic party's concern about climate change. It is a bit strange that the top feature word is 'china' while the 25th feature word is 'amendment', one would hope that is would be the opposite. There are also a lot of negative (in my opinion) words like 'crime', 'destroyed', 'enemy' and 'isis' in this list. I am also not sure why 'abraham' is top feature. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Classifying Congressional Tweets\n",
    "\n",
    "In this part we apply the classifer we just built to a set of tweets by people running for congress\n",
    "in 2018. These tweets are stored in the database `congressional_data.db`. That DB is funky, so I'll\n",
    "give you the query I used to pull out the tweets. Note that this DB has some big tables and \n",
    "is unindexed, so the query takes a minute or two to run on my machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cong_db = sqlite3.connect(\"congressional_data.db\")\n",
    "cong_cur = cong_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cong_cur.execute(\n",
    "        '''\n",
    "           SELECT DISTINCT \n",
    "                  cd.candidate, \n",
    "                  cd.party,\n",
    "                  tw.tweet_text\n",
    "           FROM candidate_data cd \n",
    "           INNER JOIN tweets tw ON cd.twitter_handle = tw.handle \n",
    "               AND cd.candidate == tw.candidate \n",
    "               AND cd.district == tw.district\n",
    "           WHERE cd.party in ('Republican','Democratic') \n",
    "               AND tw.tweet_text NOT LIKE '%RT%'\n",
    "        ''')\n",
    "\n",
    "results = list(results) # Just to store it, since the query is time consuming"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# moving on to calling functions\n",
    "for row in query_results :\n",
    "    text, party = row # each row of query result will have text and party\n",
    "    prep_text = prepare(text, pipeline= my_pipeline) # calling pipeline of functions for text\n",
    "    \n",
    "    # making tokens into string of words:\n",
    "    speeches = \" \".join(prep_text)\n",
    "    convention_data.append([speeches, party])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = []\n",
    "\n",
    "# Now fill up tweet_data with sublists like we did on the convention speeches.\n",
    "# moving on to calling functions\n",
    "for row in results :\n",
    "    candidate, party, tweet = row # each row of query result will have candidate, party, and tweet\n",
    "    decode_tweet = tweet.decode('utf-8') # decoding the tweet text so it is usable\n",
    "    prep_text = prepare(text= decode_tweet, pipeline= my_pipeline) # calling pipeline of functions for text\n",
    "    \n",
    "    # making tokens into string of words:\n",
    "    ready_tweets = \" \".join(prep_text)\n",
    "    tweet_data.append([ready_tweets, party]) # classifier didn't like having candidate in there with it so removed\n",
    "\n",
    "\n",
    "# Note that this may take a bit of time, since we have a lot of tweets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of tweets here. Let's take a random sample and see how our classifer does. I'm guessing it won't be too great given the performance on the convention speeches..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['earlier today spoke house floor abt protecting health care women praised ppmarmonte work central coast httpstcowqgtrzt7vv',\n",
       "  'Democratic'],\n",
       " ['go tribe #rallytogether httpstco0nxutfl9l5', 'Democratic'],\n",
       " ['apparently trump thinks easy students overwhelmed crushing burden debt pay student loans #trumpbudget httpstcockyqo5t0qh',\n",
       "  'Democratic'],\n",
       " ['weâ€™re grateful first responders rescue personnel firefighters police volunteers working tirelessly keep people safe provide muchneeded help putting lives line httpstcoezpv0vmiz3',\n",
       "  'Republican'],\n",
       " ['letâ€™s make even greater #kag ðŸ‡ºðŸ‡¸ httpstcoy9qozd5l2z', 'Republican'],\n",
       " ['1hr cavs tie series 22 im #allin216 repbarbaralee scared #roadtovictory',\n",
       "  'Democratic'],\n",
       " ['congrats belliottsd new gig sd city hall glad continue serveâ€¦ httpstcofkvmw3cqdi',\n",
       "  'Democratic'],\n",
       " ['really close 3500 raised toward match right whoot thatâ€™s 7000 nonmath majors room ðŸ˜‚ help us get httpstcotu34c472sd httpstcoqsdqkypsmc',\n",
       "  'Democratic'],\n",
       " ['today comment period potusâ€™s plan expand offshore drilling opened public 60 days march 9 share oppose proposed program directly trump administration comments made email mail httpstcobaaymejxqn',\n",
       "  'Democratic'],\n",
       " ['celebrated icseastlaâ€™s 22 years eastside commitment amp saluted community leaders last nightâ€™s awards dinner httpstco7v7gh8givb',\n",
       "  'Democratic']]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(20201014)\n",
    "\n",
    "tweet_data_sample = random.choices(tweet_data,k=10)\n",
    "tweet_data_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's our (cleaned) tweet: earlier today spoke house floor abt protecting health care women praised ppmarmonte work central coast httpstcowqgtrzt7vv\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: go tribe #rallytogether httpstco0nxutfl9l5\n",
      "Actual party is Democratic and our classifer says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: apparently trump thinks easy students overwhelmed crushing burden debt pay student loans #trumpbudget httpstcockyqo5t0qh\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: weâ€™re grateful first responders rescue personnel firefighters police volunteers working tirelessly keep people safe provide muchneeded help putting lives line httpstcoezpv0vmiz3\n",
      "Actual party is Republican and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: letâ€™s make even greater #kag ðŸ‡ºðŸ‡¸ httpstcoy9qozd5l2z\n",
      "Actual party is Republican and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: 1hr cavs tie series 22 im #allin216 repbarbaralee scared #roadtovictory\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: congrats belliottsd new gig sd city hall glad continue serveâ€¦ httpstcofkvmw3cqdi\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: really close 3500 raised toward match right whoot thatâ€™s 7000 nonmath majors room ðŸ˜‚ help us get httpstcotu34c472sd httpstcoqsdqkypsmc\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: today comment period potusâ€™s plan expand offshore drilling opened public 60 days march 9 share oppose proposed program directly trump administration comments made email mail httpstcobaaymejxqn\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: celebrated icseastlaâ€™s 22 years eastside commitment amp saluted community leaders last nightâ€™s awards dinner httpstco7v7gh8givb\n",
      "Actual party is Democratic and our classifer says Republican.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for tweet, party in tweet_data_sample :\n",
    "    #estimated_party = 'Gotta fill this in'\n",
    "    # call in the conv_features function on tweet\n",
    "    estimate_setup = conv_features(tweet, feature_words)\n",
    "    # running setup through classifier from nltk:\n",
    "    estimated_party = classifier.classify(estimate_setup)\n",
    "    # Fill in the right-hand side above with code that estimates the actual party\n",
    "    \n",
    "    print(f\"Here's our (cleaned) tweet: {tweet}\")\n",
    "    print(f\"Actual party is {party} and our classifer says {estimated_party}.\")\n",
    "    print(\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've looked at it some, let's score a bunch and see how we're doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of counts by actual party and estimated party. \n",
    "# first key is actual, second is estimated\n",
    "parties = ['Republican','Democratic']\n",
    "results = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for p in parties :\n",
    "    for p1 in parties :\n",
    "        results[p][p1] = 0\n",
    "\n",
    "\n",
    "num_to_score = 10000\n",
    "random.shuffle(tweet_data)\n",
    "\n",
    "for idx, tp in enumerate(tweet_data) :\n",
    "    tweet, party = tp    \n",
    "    # Now do the same thing as above, but we store the results rather\n",
    "    # than printing them. \n",
    "   \n",
    "    # get the estimated party\n",
    "    #estimated_party = \"Gotta fill this in\"\n",
    "    estimate_setup = conv_features(tweet, feature_words)\n",
    "    estimated_party = classifier.classify(estimate_setup)\n",
    "    \n",
    "    results[party][estimated_party] += 1\n",
    "    \n",
    "    if idx > num_to_score : \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'Republican': defaultdict(int,\n",
       "                         {'Republican': 3695, 'Democratic': 583}),\n",
       "             'Democratic': defaultdict(int,\n",
       "                         {'Republican': 4817, 'Democratic': 907})})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflections\n",
    "\n",
    "Similar to the speeches, most key words come from Republican speeches and most of the tweets are being classified as coming from Republicans since we used the same key words for classification. Looking back at the accuracy of the model (seen in this line of code: classifier = nltk.NaiveBayesClassifier.train(train_set)) the classifier was only 50% accurate. Once could argue you could flip a coin or classify all the tweeters as Republican and be right half the time, like with the model.  \n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
